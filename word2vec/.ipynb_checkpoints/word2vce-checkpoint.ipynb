{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec\n",
    "---\n",
    "Word2Vec 是一种著名的 词嵌入（Word Embedding） 方法，它可以计算每个单词在其给定语料库环境下的 分布式词向量（Distributed Representation，亦直接被称为词向量）。词向量表示可以在一定程度上刻画每个单词的语义。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单用法\n",
    "---\n",
    "### 读取语料\n",
    "---\n",
    "* class gensim.models.word2vec.BrownCorpus（dirname ）\n",
    "从布朗语料库（NLTK数据的一部分）迭代句子,dirname是存储布朗语料库的根目录(通过nltk.download()下载布朗语料库)，得到的这个对象可以通过循环迭代语料库的句子。\n",
    "\n",
    "* class gensim.models.word2vec.LineSentence(source, max_sentence_length=10000, limit=None)\n",
    "与上一样，也是产生迭代器，但需要更改下文件格式。简单的格式：一篇文档=一行; 单词已经过预处理并由空格分隔。\n",
    "\n",
    "* class gensim.models.word2vec.PathLineSentences（source，max_sentence_length = 10000，limit = None ）\n",
    "与LineSentence类一样，不过这里是处理根目录下的所有文件，同样文件中句子格式需要处理\n",
    "\n",
    "* class gensim.models.word2vec.Text8Corpus（fname，max_sentence_length = 10000 ）\n",
    "从text8语料库中迭代句子\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "file_path = 'word2vec训练数据.txt'\n",
    "# 使用LineSentence读取语料\n",
    "sentences = word2vec.LineSentence(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练word2vec语义向量\n",
    "---\n",
    "```python\n",
    "class gensim.models.word2vec.Word2Vec(sentences=None, size=100, alpha=0.025, window=5, min_count=5,  \n",
    "                   max_vocab_size=None, sample=1e-3, seed=1, workers=3, min_alpha=0.0001,  \n",
    "                   sg=0, hs=0, negative=5, ns_exponent=0.75, cbow_mean=1, hashfxn=hash, iter=5, null_word=0,  \n",
    "                   trim_rule=None, sorted_vocab=1, batch_words=MAX_WORDS_IN_BATCH, compute_loss=False, callbacks=(),  \n",
    "                   max_final_vocab=None)  \n",
    "```\n",
    "* sentence(iterable of iterables):可迭代的句子可以是简单的list，但对于较大的语料库，可以考虑直接从磁盘/网络传输句子的迭代。见BrownCorpus，Text8Corpus 或LineSentence.\n",
    "* SG(INT {1 ，0}) -定义的训练算法。如果是1，则使用skip-gram; 否则，使用CBOW。\n",
    "* hs：是否采用基于Hierarchical Softmax的模型。参数为1表示使用，0表示不使用\n",
    "* size(int) - 特征向量的维数。\n",
    "* window(int) - 句子中当前词和预测词之间的最大距离。\n",
    "* min_count(int) - 忽略总频率低于此值的所有单词。 \n",
    "\n",
    "    关于Hierarchical Softmax与negative sampling，可以参考以下博客:  \n",
    "        http://www.cnblogs.com/pinard/p/7243513.html  \n",
    "        https://www.cnblogs.com/pinard/p/7249903.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(sentences, hs=1,min_count=1,window=2,size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存模型\n",
    "---\n",
    "model.save(file_name)\n",
    "* file_name:存储模型的名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_word2vec_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载模型\n",
    "---\n",
    "word2vec.Word2Vec.load(file_name)\n",
    "* file_name:存储的模型的名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec.load('model_word2vec_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.22426838,  0.02633552, -0.02290411,  0.14525431,  0.01981955,\n",
       "        0.13089268, -0.12066922,  0.10393241,  0.01295518,  0.19346932,\n",
       "        0.10436867,  0.14000842, -0.03831108, -0.18611042, -0.07669395,\n",
       "       -0.08514451,  0.03965911, -0.00318339,  0.16243516, -0.16340742,\n",
       "       -0.33707017,  0.07755363,  0.12572414, -0.11797849,  0.1653443 ,\n",
       "        0.30564123, -0.00515249,  0.18454236, -0.06155895, -0.05593882,\n",
       "       -0.10479842,  0.03347127, -0.17359632, -0.05874354,  0.19829811,\n",
       "        0.01264181,  0.22997355,  0.29887694, -0.0103536 ,  0.05097369,\n",
       "       -0.26170415,  0.05271434,  0.4314007 , -0.19348401, -0.17331848,\n",
       "       -0.10159525, -0.20982312,  0.07776938, -0.03535717,  0.1256921 ,\n",
       "        0.12042744, -0.24314827,  0.29370874, -0.18564339, -0.01756079,\n",
       "       -0.01981601,  0.23581013,  0.19336703, -0.23828499, -0.1780822 ,\n",
       "       -0.18261431,  0.07098646,  0.12981512, -0.00393073,  0.47541967,\n",
       "        0.40531647, -0.09605374, -0.02490463, -0.19722001, -0.12233974,\n",
       "        0.08034348, -0.03766701,  0.16495067, -0.19109172,  0.08571786,\n",
       "       -0.07530445,  0.19882925, -0.06613968,  0.1956275 ,  0.05102437,\n",
       "       -0.1345634 ,  0.37527272, -0.27111363, -0.29487646, -0.15915117,\n",
       "       -0.09209093, -0.05671251,  0.2536157 , -0.36535704,  0.00084421,\n",
       "       -0.11014175,  0.22758168,  0.09507579, -0.24244666,  0.27789003,\n",
       "       -0.08471345,  0.31941074,  0.3314283 ,  0.00821773, -0.13666806,\n",
       "       -0.3335687 ,  0.1110599 ,  0.18725452, -0.0568226 ,  0.29508412,\n",
       "       -0.05539918, -0.03196736, -0.04358312, -0.00741066,  0.22866268,\n",
       "       -0.08740785,  0.32536042, -0.161118  , -0.11780106, -0.34255195,\n",
       "       -0.02023171, -0.3504385 ,  0.33536202, -0.0094815 , -0.34308302,\n",
       "       -0.03798261,  0.24307947, -0.1269174 ,  0.05390645,  0.18626335,\n",
       "       -0.11594059,  0.12619923, -0.00048885], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取单词word2vec值\n",
    "model['apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68497026\n",
      "0.97141504\n",
      "0.97978044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n",
      "C:\\Anaconda\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# 计算两个单词的语义相似度\n",
    "print(model.similarity('魅族','全网通'))\n",
    "print(model.similarity('16g','64g'))\n",
    "print(model.similarity('粉色','金色'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网上中文语料库\n",
    "腾讯AI实验室宣布，正式开源一个大规模、高质量的中文词向量数据集  \n",
    "https://ai.tencent.com/ailab/nlp/embedding.html  \n",
    "120G+训练好的word2vec模型（中文词向量）  \n",
    "https://blog.csdn.net/tu_22/article/details/79035769  \n",
    "还有一些开源语料库，可以自己拿去训练。。。。。。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
